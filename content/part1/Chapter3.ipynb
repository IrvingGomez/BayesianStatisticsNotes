{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the posterior distribution follows the same parametric structure than the prior distribution, we say that we have a conjugate model.\n",
    "\n",
    "Formally, if $p(Y|\\theta)\\in\\mathcal{F}$ and $\\mathcal{P}$ is a family of prior distributions for $\\theta$, then $\\mathcal{P}$ is conjugate for $\\mathcal{F}$ if $p(\\theta|\\mathbf{Y})\\in\\mathcal{P}$ for all $p(\\cdot|\\theta)\\in\\mathcal{F}$ and $p(\\cdot)\\in\\mathcal{P}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate models for the exponential family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the likelihood of the data follows a distribution of the exponential family of distributions, it is possible to obtain the form of the prior conjugate.\n",
    "\n",
    "Let be $p(Y|\\theta)\\in\\mathcal{F}$, where $\\mathcal{F}$ is the exponential family of distributions. Then, by the Fisher's factorization theorem, $p(Y|\\theta)$ can be expressed as:\n",
    "$$p(Y|\\theta)=f(y)g(\\theta)\\exp\\left\\lbrace\\phi^T(\\theta)u(y)\\right\\rbrace,$$\n",
    "\n",
    "where $\\phi(\\theta)$ and $u(y)$ are, in general, of the same dimension than $\\theta$, $\\phi(\\theta)$ is called the natural parameter of the family $\\mathcal{F}$.\n",
    "\n",
    "If $Y_1,\\ldots,Y_n$ are random variables independent and identically distributed, then\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\mathbf{Y}|\\theta) &= \\left(\\prod_{i=1}^n f(y_i)\\right)g^n(\\theta)\\exp\\left\\lbrace\\phi^T(\\theta)\\sum_{i=1}^n u(y_i)\\right\\rbrace \\\\\n",
    "&\\propto g^n(\\theta)e^{\\phi^T(\\theta)t(\\mathbf{y}),}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $t(\\mathbf{y})=\\sum_{i=1}^n u(y_i)$ is called the sufficient and minimal.\n",
    "\n",
    "If we consider the prior of the form\n",
    "\n",
    "$$p(\\theta)\\propto g(\\theta)^\\eta e^{\\phi^T(\\theta)\\xi},$$ \n",
    "\n",
    "then\n",
    "\n",
    "$$p(\\theta|\\mathbf{Y})\\propto g(\\theta)^{n+\\eta}e^{\\phi^T(\\theta)(\\xi+t(\\mathbf{y}))}.$$\n",
    "\n",
    "Moreover, note that, due to the structure, we can interpret $\\eta$ as the \"size\" of the sample *a priori*  and $\\xi$ as the \"sufficient and minimal statistic\" *a priori*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial distribution\n",
    "\n",
    "Let be $Y_1,\\ldots,Y_n|\\theta\\overset{iid}{\\sim}\\textsf{Bernoulli}(\\theta)$, then\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\mathbf{Y}|\\theta) & = \\theta^{\\sum_{i=1}^n y_i}(1-\\theta)^{n-\\sum_{i=1}^n y_i} \\underbrace{\\prod_{i=1}^n 1_{\\{0,1\\}}(y_i)}_{f(\\mathbf{y})} \\\\\n",
    "& = f(\\mathbf{y})\\exp\\left\\lbrace\\sum_{i=1}^n y_i\\log\\theta + \\left(n-\\sum_{i=1}^n y_i\\right)\\log (1-\\theta)\\right\\rbrace \\\\\n",
    "& = f(\\mathbf{y})\\exp\\left\\lbrace n \\log (1-\\theta) + \\sum_{i=1}^n y_i\\log\\frac{\\theta}{1-\\theta}\\right\\rbrace \\\\\n",
    "& = f(\\mathbf{y})\\underbrace{(1-\\theta)^n}_{g(\\theta)^n}\\exp\\underbrace{\\left\\lbrace\\sum_{i=1}^n y_i\\log\\frac{\\theta}{1-\\theta}\\right\\rbrace}_{t(\\mathbf{y})\\phi(\\theta)} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, the conjugate prior is given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\theta) & \\propto (1-\\theta)^\\eta\\exp\\left\\lbrace\\xi\\log\\frac{\\theta}{1-\\theta}\\right\\rbrace \\\\\n",
    "& = (1-\\theta)^{\\eta-\\xi}\\theta^{\\xi},\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "note that we can interpreate $\\eta$ and $\\xi$ as:\n",
    "\n",
    "- $\\eta$: number of Bernoulli experiments *a priori*,\n",
    "- $\\xi$: number of successes *a priori*,\n",
    "\n",
    "so $\\eta-\\xi$ wpuld be the number of fails *a priori*.\n",
    "\n",
    "Let be $\\alpha-1=\\xi$ and $\\beta-1=\\eta-\\xi$, then the conjugate prior can be expressed as\n",
    "\n",
    "$$p(\\theta)\\propto \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1},$$\n",
    "\n",
    "which we recognize as the kernelr of a distrbution $\\textsf{Beta}(\\alpha,\\beta)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson distribution\n",
    "\n",
    "Let be $Y_1,\\ldots,Y_n|\\theta\\overset{iid}{\\sim}\\textsf{Poisson}(\\theta)$, then\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\mathbf{Y}|\\theta) & = \\underbrace{\\left\\lbrack\\prod_{i=1}^n \\frac{1}{y_i!}1_{\\{0,1,\\ldots\\}}(y_i)\\right\\rbrack}_{f(\\mathbf{y})}\\theta^{\\sum_{i=1}^n y_i}\\exp\\{-n\\theta\\} \\\\\n",
    "& = f(\\mathbf{y})\\underbrace{\\left(e^{-\\theta}\\right)^n}_{g(\\theta)^n}\\exp\\underbrace{\\left\\{\\sum_{i=1}^n y_i\\log\\theta\\right\\}}_{t(\\mathbf{y})\\phi(\\theta)}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, the conjugate prior is given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\theta) & \\propto e^{-\\eta\\theta}\\exp\\{\\xi\\log\\theta\\} \\\\\n",
    "& = \\theta^\\xi e^{-\\eta\\theta}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Let be $\\xi=\\alpha-1$ and $\\eta=\\beta$, then the conjugate prior might be expressed as\n",
    "\n",
    "$$p(\\theta)\\propto\\theta^{\\alpha-1}e^{-\\beta\\theta},$$\n",
    "\n",
    "which we recognize as the kernel of a distribution $\\textsf{Gama}(\\alpha,\\beta)$.\n",
    "\n",
    "Note that $\\alpha-1$ is equivalent as the sum of prior counts and $\\beta$ the number of prior experiments. Therefore, if we haven't done experiments previously, we can set $\\alpha=1$ and $\\beta=0$, in such case $p(\\theta)\\propto 1_{(0,\\infty)}(\\theta)$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
