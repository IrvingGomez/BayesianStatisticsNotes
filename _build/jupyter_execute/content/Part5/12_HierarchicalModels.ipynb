{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General framework\n",
    "\n",
    "In their simplest version, in hierarchical models the parameters $\\theta_j$ come from a random sample of the prior distribution, which is determined by a vector of hyperparamters $\\phi$, that is\n",
    "\n",
    "$$p(\\theta|\\phi)=\\prod_{j=1}^J p(\\theta_j|\\phi).$$\n",
    "\n",
    "In general $\\phi$ is unknown and, this, has its own (hyper)prior distribution $p(\\phi)$.\n",
    "\n",
    "Thus, the joint prior distribution is\n",
    "\n",
    "$$p(\\theta,\\phi)=p(\\theta|\\phi)p(\\phi),$$\n",
    "\n",
    "and the joint posterior distribution satisfies that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\theta,\\phi|\\mathbf{Y}) & \\propto p(\\theta,\\phi) p(\\mathbf{Y}|\\theta,\\phi) \\\\\n",
    "& = p(\\theta,\\phi) p(\\mathbf{Y}|\\theta) \\\\\n",
    "& = p(\\theta|\\phi) p(\\phi) p(\\mathbf{Y}|\\theta).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "When specifying a prior distribution for $\\phi$, we have to take special care when an improper distribution is used and check that the posterior distribution exists, this usually requires a tremendous mathematical effort. We can avoid this problem if we restrict the hyperprior to be a proper distribution.\n",
    "\n",
    "### Posterior conditional distribution of $\\theta$, $p(\\theta|\\phi,\\mathbf{Y})$\n",
    "\n",
    "Note that the posterior conditional of $\\theta$ satisfies\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\theta|\\phi,\\mathbf{Y}) &\\propto p(\\theta|\\phi) p(\\mathbf{Y}|\\theta) \\\\\n",
    "& = f(\\phi,\\mathbf{Y}) p(\\theta|\\phi) p(\\mathbf{Y}|\\theta).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $f(\\phi,\\mathbf{Y})$ is the \"constant\" of proportionality, which depens on $\\phi$ and $\\mathbf{Y}$.\n",
    "\n",
    "### Posterior distribution of $\\phi$, $p(\\phi|\\mathbf{Y})$\n",
    "\n",
    "The posterior of $\\phi$ can be calculated marginalizing the joint posterior with respect to $\\theta$, that is\n",
    "\n",
    "$$p(\\phi|\\mathbf{Y})=\\int p(\\theta,\\phi|\\mathbf{Y})d\\theta.$$\n",
    "\n",
    "Or, using the formula of conditional probability:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\phi|\\mathbf{Y}) &= \\frac{p(\\theta,\\phi|\\mathbf{Y})}{p(\\theta|\\phi,\\mathbf{Y})} \\\\\\\\\n",
    "&\\propto \\frac{p(\\theta|\\phi) p(\\phi) p(\\mathbf{Y}|\\theta)}{f(\\phi,\\mathbf{Y}) p(\\theta|\\phi) p(\\mathbf{Y}|\\theta)} \\\\\\\\\n",
    "&\\propto \\frac{p(\\phi)}{f(\\phi,\\mathbf{Y})}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rat tumor\n",
    "\n",
    "This example was taken from section 3.7 of {cite}`gelman2013bayesian`. The data for the example was taken from {cite}`tarone1982use`. The code with all the details is [20_RatTumorEmpiricalFullBayes.ipynb](https://github.com/IrvingGomez/BayesianStatistics/blob/main/Codes/20_RatTumorEmpiricalFullBayes.ipynb) in the [repository of the course](https://github.com/IrvingGomez/BayesianStatistics).\n",
    "\n",
    "As commented previously, in the evaluation of drugs for possible clinical application, studies are routinely performed on rodents. For a particular study the immediate aim is to estimate $\\theta$, the probability of tumor in a population of female laboratory rats that receive a zero dose of the drug (a control group). The data show that 4 out of 14 rats developed endometrial stromal polyps (a kind of tumor). It is natural to assume a binomial model for the number of tumors, given $\\theta$. For convenience, we select a prior distribution for $\\theta$ from the conjugate family, $\\theta\\sim\\textsf{Beta}(\\alpha,\\beta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Bayes\n",
    "\n",
    "Using the historical data and the method of moments we can set some values for $\\alpha$ and $\\beta$. Since $\\theta\\sim\\textsf{Beta}(\\alpha,\\beta)$, then $$\\mathbb{E}(\\theta)=\\frac{\\alpha}{\\alpha+\\beta}\\text{ and }\\mathbb{V}(\\theta)=\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}.$$ Let be $\\bar{Y}_j=Y_j/n_j$, $\\bar{\\bar Y}$ the mean of $\\bar Y_1,\\ldots,\\bar Y_J$, and $s_{\\bar{Y}}^2$ their variance.\n",
    "\n",
    "Then, we have to find the values of $\\alpha$ and $\\beta$ such that\n",
    "$$\\bar{\\bar Y}=\\frac{\\alpha}{\\alpha+\\beta} \\text{ and }s_{\\bar{Y}}^2=\\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}.$$\n",
    "\n",
    "Solving these equations, we find that $$\\beta = \\alpha\\left(\\frac{1-\\bar{\\bar Y}}{\\bar{\\bar Y}}\\right)\\text{ and }\\alpha = \\frac{\\bar{\\bar Y}^2(1-\\bar{\\bar Y})-\\bar{\\bar Y}s_{\\bar{Y}}^2}{s_{\\bar{Y}}^2}.$$\n",
    "\n",
    "Using this simple estimate of the historical population distribution as a prior distribution for the current experiment yields a Beta($5.356,18.615$) posterior distribution for $\\theta$.\n",
    "\n",
    "The next figure shows the posterior distribuion of $\\theta$, with a vertical line is the observed proportion 4/14.\n",
    "\n",
    "```{image} Images/PosteriorThetaEmpirical.png\n",
    ":alt: PosteriorThetaEmpirical\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Note that the prior information has resulted in a posterior distribution substantially lower than the crude proportion 4/14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Bayesian approach\n",
    "\n",
    "When we use the estimated values for $\\alpha$ and $\\beta$, we act as if those values where the real ones, which eliminates all the uncertainty that we have on the hyperparameters. Instead of this empirical approach, we can choose for a full Bayesian approach and assign a hyperprior for $\\alpha$ and $\\beta$. Assume that we have $J$ historical data, and model\n",
    "\n",
    "$$Y_j|\\theta_j\\sim\\textsf{Binomial}(n_j,\\theta_j),$$\n",
    "\n",
    "with the number of rats, $n_j$ known, and\n",
    "\n",
    "$$\\theta_j\\sim\\textsf{Beta}(\\alpha,\\beta).$$\n",
    "\n",
    "We just need to specify a prior for $(\\alpha,\\beta)$, but we have to check that the posterior exists.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\theta,\\alpha,\\beta|\\mathbf{Y}) &\\propto p(\\alpha,\\beta)p(\\theta|\\alpha,\\beta)p(\\mathbf{Y}|\\theta) \\\\\\\\\n",
    "&\\propto p(\\alpha,\\beta)\\prod_{j=1}^J \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta_j^{\\alpha-1}(1-\\theta_j)^{\\beta-1}\\prod_{j=1}^J \\theta_j^{Y_j}(1-\\theta_j)^{1-Y_j}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$p(\\theta|\\alpha,\\beta,\\mathbf{Y}) \\propto \\prod_{j=1}^J \\theta_j^{\\alpha+Y_j-1}(1-\\theta_j)^{\\beta+n_j-Y_j-1}.$$\n",
    "\n",
    "That is, given $\\alpha$ and $\\beta$, the elements of $\\theta$ are independent and follow a beta distribution\n",
    "\n",
    "$$\\theta_j|\\alpha,\\beta,\\mathbf{Y}\\sim\\textsf{Beta}(\\alpha+Y_j,\\beta+n_j-Y_j),$$\n",
    "\n",
    "so\n",
    "\n",
    "$$p(\\theta|\\alpha,\\beta,\\mathbf{Y}) = \\prod_{j=1}^J \\frac{\\Gamma(\\alpha+\\beta+n_j)}{\\Gamma(\\alpha+Y_j)\\Gamma(\\beta+n_j-Y_j)}\\theta_j^{\\alpha+Y_j-1}(1-\\theta_j)^{\\beta+n_j-Y_j-1}.$$\n",
    "\n",
    "Expressing $p(\\theta|\\alpha,\\beta,\\mathbf{Y})$ as:\n",
    "\n",
    "$$p(\\theta|\\alpha,\\beta,\\mathbf{Y}) = f(\\alpha,\\beta,\\mathbf{Y})p(\\theta|\\alpha,\\beta)p(\\mathbf{Y}|\\theta),$$\n",
    "\n",
    "we get that\n",
    "\n",
    "$$f(\\alpha,\\beta,\\mathbf{Y}) = \\prod_{j=1}^J \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}\\frac{\\Gamma(\\alpha+\\beta+n_j)}{\\Gamma(\\alpha+Y_j)\\Gamma(\\beta+n_j-Y_j)}\\left[\\binom {n_j}{Y_j}\\right]^{-1}.$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$p(\\alpha,\\beta|\\mathbf{Y})\\propto p(\\alpha,\\beta)\\prod_{j=1}^J\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\frac{\\Gamma(\\alpha+Y_j)\\Gamma(\\beta+n_j-Y_j)}{\\Gamma(\\alpha+\\beta+n_j)}.$$\n",
    "\n",
    "In {cite}`gelman2013bayesian`, the authors proposed the noninformative prior $p(\\alpha,\\beta)\\propto(\\alpha+\\beta)^{-5/2}$, which yields a proper posterior distribution.\n",
    "\n",
    "The next figure shows the marginal posterior distributions of $\\alpha$ and $\\beta$, the vertical lines represent their empirical estimators. Note that in both cases they understimate the possible values for $\\alpha$ and $\\beta$.\n",
    "\n",
    "```{image} Images/PosteriorAlphaBetaMarginal.png\n",
    ":alt: PosteriorThetaEmpirical\n",
    ":align: center\n",
    "```\n",
    "\n",
    "In the next figure I present the joint posterior of $\\alpha$ and $\\beta$, note that the joint posterior is far from a gaussian distribution. This is a typical behavior for hyperparameters in hierarchical models.\n",
    "\n",
    "```{image} Images/PosteriorAlphaBetaJoint.png\n",
    ":alt: PosteriorThetaEmpirical\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Finally the nect image shows credible intervals for all the $\\theta_j$, $j=1,\\ldots,J$ against their observed proportions. Note that cases where the proportion is low tend to be move upward, and viceversa, when the proportion is high the posterior estimator tends to move downward\n",
    "\n",
    "```{image} Images/PosteriorThetaFull.png\n",
    ":alt: PosteriorThetaEmpirical\n",
    ":align: center\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}